{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from args import parse_args\n",
    "from baselines import *\n",
    "from data_utils import (\n",
    "    get_data_stat,\n",
    "    get_natural_imbalanced_split_data,\n",
    "    get_step_imbalanced_split_data,\n",
    "    load_data,\n",
    ")\n",
    "from bat import BatAugmenter\n",
    "from trainer import NodeClassificationTrainer\n",
    "from utils import get_model, get_device, print_centered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Experiment\n",
    "\n",
    "This script will run experiments on all the combinations of following settings (specified by the global variables below):\n",
    "\n",
    "| Setting         | (Default) Values                           | Description                                                        |\n",
    "| --------------- | ------------------------------------------ | ------------------------------------------------------------------ |\n",
    "| `DATASET_SPACE` | `['cora', 'citeseer', 'pubmed']`           | The datasets to use.                                               |\n",
    "| `IMB_TYPES`     | `{'step': [10, 20], 'natural': [50, 100]}` | The imbalance types and ratios.                                    |\n",
    "| `BAT_MODES`    | `['dummy', 'bat0', 'bat1']`                 | The BAT modes to test, `dummy` means no topological augmentation. |\n",
    "\n",
    "For other settings, we use the default values specified in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Experiment Setup \"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.argv = [\"\"]\n",
    "args = parse_args()\n",
    "\n",
    "DATASET_SPACE = [\"citeseer\"]\n",
    "MODE_SPACE = [\"dummy\", \"bat0\", \"bat1\"]\n",
    "IMB_SPACE = {\n",
    "    \"step\": [10, 20],\n",
    "    \"natural\": [50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using GPU #0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Run experiment with\n",
      "  - Datasets:        ['citeseer']\n",
      "  - BAT modes:      ['dummy', 'bat0', 'bat1']\n",
      "  - Imbalance types: {'step': [10, 20], 'natural': [50, 100]}\n",
      "\n",
      "============== Arguments ==============\n",
      "gpu_id       : 0\n",
      "seed         : 42\n",
      "n_runs       : 5\n",
      "debug        : True\n",
      "dataset      : cora\n",
      "imb_type     : step\n",
      "imb_ratio    : 10\n",
      "gnn_arch     : GCN\n",
      "n_layer      : 3\n",
      "hid_dim      : 256\n",
      "lr           : 0.01\n",
      "weight_decay : 0.0005\n",
      "epochs       : 2000\n",
      "early_stop   : 200\n",
      "tqdm         : False\n",
      "bat_mode     : all\n",
      "========================================\n",
      "\n",
      "////////////////////////// Experiment: Imbalance Type [Step] - Ratio [10] //////////////////////////\n",
      "\n",
      "============================ Dataset [Citeseer] - Independent Runs [5] ============================\n",
      "===================== Setting: Dataset [Citeseer] - StepIR [10] - BAT [dummy] =====================\n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   43\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 1: Best Epoch:   58 | train/val/test | ACC: 100.0/44.00/39.80 | BACC: 100.0/41.18/41.85 | MACRO-F1: 100.0/32.78/32.72 | aug time: 0.00ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   44\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 2: Best Epoch:  145 | train/val/test | ACC: 100.0/49.00/42.70 | BACC: 100.0/46.28/43.81 | MACRO-F1: 100.0/40.85/37.72 | aug time: 0.00ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   45\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 3: Best Epoch:  100 | train/val/test | ACC: 100.0/35.40/32.80 | BACC: 100.0/36.87/36.42 | MACRO-F1: 100.0/28.10/26.90 | aug time: 0.00ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   46\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 4: Best Epoch:  193 | train/val/test | ACC: 100.0/41.00/34.60 | BACC: 100.0/40.19/37.56 | MACRO-F1: 100.0/32.29/28.95 | aug time: 0.00ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   47\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 5: Best Epoch:   15 | train/val/test | ACC: 84.85/33.80/31.70 | BACC: 46.67/34.80/34.97 | MACRO-F1: 44.48/21.74/21.45 | aug time: 0.00ms \n",
      "Avg Test Performance (5 runs):  | ACC: 36.32 ± 1.89 | BACC: 38.92 ± 1.50 | MACRO-F1: 29.55 ± 2.45\n",
      "====================== Setting: Dataset [Citeseer] - StepIR [10] - BAT [bat0] ======================\n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   43\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 1: Best Epoch:  220 | train/val/test | ACC: 100.0/64.00/63.40 | BACC: 100.0/60.65/61.27 | MACRO-F1: 100.0/59.66/60.61 | aug time: 14.19ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   44\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 2: Best Epoch:  152 | train/val/test | ACC: 100.0/52.20/49.20 | BACC: 100.0/48.46/47.15 | MACRO-F1: 100.0/44.41/42.67 | aug time: 14.49ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   45\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 3: Best Epoch:  147 | train/val/test | ACC: 100.0/62.60/60.40 | BACC: 100.0/58.94/58.56 | MACRO-F1: 100.0/58.65/58.35 | aug time: 15.42ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   46\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 4: Best Epoch:  347 | train/val/test | ACC: 100.0/57.00/54.20 | BACC: 100.0/54.70/52.06 | MACRO-F1: 100.0/53.57/51.45 | aug time: 15.83ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   47\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 5: Best Epoch:  237 | train/val/test | ACC: 100.0/62.20/59.30 | BACC: 100.0/59.33/56.93 | MACRO-F1: 100.0/58.38/56.67 | aug time: 15.88ms \n",
      "Avg Test Performance (5 runs):  | ACC: 57.30 ± 2.25 | BACC: 55.19 ± 2.24 | MACRO-F1: 53.95 ± 2.86\n",
      "====================== Setting: Dataset [Citeseer] - StepIR [10] - BAT [bat1] ======================\n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   43\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 1: Best Epoch:  251 | train/val/test | ACC: 100.0/62.80/61.90 | BACC: 100.0/59.34/59.50 | MACRO-F1: 100.0/58.55/59.00 | aug time: 15.98ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   44\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n",
      "Run 2: Best Epoch:  156 | train/val/test | ACC: 100.0/55.40/49.80 | BACC: 100.0/48.20/45.62 | MACRO-F1: 100.0/47.43/43.76 | aug time: 16.35ms \n",
      "Loading dataset Citeseer... Done!\n",
      "Generating step imbalanced task...\n",
      "-----------------------------------\n",
      "imbratio:                      10\n",
      "random_seed:                   45\n",
      "Head/Tail class number:        3/3\n",
      "Head/Tail class size:          20/2\n",
      "Classes:                       [0, 1, 2, 3, 4, 5]\n",
      "Tail classes:                  [3, 4, 5]\n",
      "Original train class counts:   [20, 20, 20, 20, 20, 20]\n",
      "Train class counts:            [20, 20, 20, 2, 2, 2]\n",
      "\n",
      "Data statistics:\n",
      "----------------\n",
      "Imabalanced?:      True\n",
      "n_node:            3327\n",
      "n_feat:            3703\n",
      "n_edge:            9104\n",
      "n_class:           6\n",
      "classes:           [0, 1, 2, 3, 4, 5]\n",
      "train_class_distr: [20, 20, 20, 2, 2, 2]\n",
      "valid_class_distr: [29, 86, 116, 106, 94, 69]\n",
      "test_class_distr:  [77, 182, 181, 231, 169, 160]\n",
      "tail_classes:      [3, 4, 5]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 101\u001b[0m\n\u001b[0;32m     86\u001b[0m trainer \u001b[38;5;241m=\u001b[39m NodeClassificationTrainer(\n\u001b[0;32m     87\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     88\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m     99\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# train the GNN with BAT augmentation\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# print best results\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\trainer.py:362\u001b[0m, in \u001b[0;36mNodeClassificationTrainer.train\u001b[1;34m(self, train_epoch, eval_freq, verbose_freq, return_best_model)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# evaluate the model on the validation set every eval_freq epochs\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 362\u001b[0m     eval_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_scores\u001b[38;5;241m.\u001b[39mappend([epoch, eval_results])\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;66;03m# compute the average validation score for model selection\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\trainer.py:274\u001b[0m, in \u001b[0;36mNodeClassificationTrainer.model_eval\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# loop over each evaluation metric and compute the metric for each dataset (train/val/test)\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_name, (metric_func, metric_kwargs) \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 274\u001b[0m     results[metric_name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    275\u001b[0m         data_name: metric_func(\n\u001b[0;32m    276\u001b[0m             y_true[data_mask], y_pred[data_mask], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetric_kwargs\n\u001b[0;32m    277\u001b[0m         )\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m data_name, data_mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_masks\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    279\u001b[0m     }\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# return the evaluation results\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\trainer.py:275\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# loop over each evaluation metric and compute the metric for each dataset (train/val/test)\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_name, (metric_func, metric_kwargs) \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    274\u001b[0m     results[metric_name] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 275\u001b[0m         data_name: metric_func(\n\u001b[0;32m    276\u001b[0m             y_true[data_mask], y_pred[data_mask], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetric_kwargs\n\u001b[0;32m    277\u001b[0m         )\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m data_name, data_mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_masks\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    279\u001b[0m     }\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# return the evaluation results\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2797\u001b[0m, in \u001b[0;36mbalanced_accuracy_score\u001b[1;34m(y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[0;32m   2719\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2720\u001b[0m     {\n\u001b[0;32m   2721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2727\u001b[0m )\n\u001b[0;32m   2728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbalanced_accuracy_score\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, adjusted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2729\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the balanced accuracy.\u001b[39;00m\n\u001b[0;32m   2730\u001b[0m \n\u001b[0;32m   2731\u001b[0m \u001b[38;5;124;03m    The balanced accuracy in binary and multiclass classification problems to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2795\u001b[0m \u001b[38;5;124;03m    0.625\u001b[39;00m\n\u001b[0;32m   2796\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2797\u001b[0m     C \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2798\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2799\u001b[0m         per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(C) \u001b[38;5;241m/\u001b[39m C\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\_classification.py:506\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# intersect y_pred, y_true with labels, eliminate items not in labels\u001b[39;00m\n\u001b[0;32m    505\u001b[0m ind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogical_and(y_pred \u001b[38;5;241m<\u001b[39m n_labels, y_true \u001b[38;5;241m<\u001b[39m n_labels)\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    507\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred[ind]\n\u001b[0;32m    508\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true[ind]\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:2675\u001b[0m, in \u001b[0;36mall\u001b[1;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_all_dispatcher)\n\u001b[0;32m   2590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mall\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2591\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2592\u001b[0m \u001b[38;5;124;03m    Test whether all array elements along a given axis evaluate to True.\u001b[39;00m\n\u001b[0;32m   2593\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2673\u001b[0m \n\u001b[0;32m   2674\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction_any_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:102\u001b[0m, in \u001b[0;36m_wrapreduction_any_all\u001b[1;34m(obj, ufunc, method, axis, out, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, \u001b[38;5;28mbool\u001b[39m, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = get_device(args.gpu_id)\n",
    "log_width = 100\n",
    "\n",
    "print(\n",
    "    f\"Run experiment with\\n\"\n",
    "    f\"  - Datasets:        {DATASET_SPACE}\\n\"\n",
    "    f\"  - BAT modes:      {MODE_SPACE}\\n\"\n",
    "    f\"  - Imbalance types: {IMB_SPACE}\\n\"\n",
    ")\n",
    "\n",
    "print_centered(\"Arguments\", 40, fillchar=\"=\")\n",
    "kwlen = max([len(k) for k in args.__dict__.keys()]) + 1\n",
    "for keys, values in args.__dict__.items():\n",
    "    print(f\"{keys:{kwlen}}: {values}\")\n",
    "print_centered(\"\", 40, fillchar=\"=\")\n",
    "\n",
    "# run the experiment\n",
    "\n",
    "for imb_type in IMB_SPACE.keys():  # loop over imbalance types\n",
    "\n",
    "    for imb_ratio in IMB_SPACE[imb_type]:  # loop over imbalance ratios\n",
    "\n",
    "        print_centered(\n",
    "            f\"Experiment: Imbalance Type [{imb_type.title()}] - Ratio [{imb_ratio}]\",\n",
    "            log_width,\n",
    "            fillchar=\"/\",\n",
    "            prefix=\"\\n\",\n",
    "        )\n",
    "\n",
    "        for dataset in DATASET_SPACE:  # loop over datasets\n",
    "\n",
    "            print_centered(\n",
    "                f\"Dataset [{dataset.title()}] - Independent Runs [{args.n_runs}]\", log_width, fillchar=\"=\", prefix=\"\\n\"\n",
    "            )\n",
    "\n",
    "            args.imb_type = imb_type\n",
    "            args.imb_ratio = imb_ratio\n",
    "            args.dataset = dataset\n",
    "\n",
    "            for bat_mode in MODE_SPACE:  # loop over BAT modes\n",
    "\n",
    "                print_centered(\n",
    "                    f\"Setting: Dataset [{args.dataset.title()}] - {args.imb_type.title()}IR [{args.imb_ratio}] - BAT [{bat_mode}]\",\n",
    "                    log_width,\n",
    "                    fillchar=\"=\",\n",
    "                )\n",
    "\n",
    "                best_results = []\n",
    "                for i_run in range(1, args.n_runs + 1):\n",
    "                    seed = args.seed + i_run\n",
    "\n",
    "                    # load imbalanced data\n",
    "                    data = load_data(args.dataset, to_device=device, verbose=args.debug)\n",
    "                    if args.imb_type == \"step\":\n",
    "                        data = get_step_imbalanced_split_data(\n",
    "                            data,\n",
    "                            imbratio=args.imb_ratio,\n",
    "                            random_seed=seed,\n",
    "                            verbose=args.debug,\n",
    "                        )\n",
    "                    elif args.imb_type == \"natural\":\n",
    "                        data = get_natural_imbalanced_split_data(\n",
    "                            data,\n",
    "                            imbratio=args.imb_ratio,\n",
    "                            random_seed=seed,\n",
    "                            verbose=args.debug,\n",
    "                        )\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"imb_type must be one of ['step', 'natural'], got {args.imb_type}.\"\n",
    "                        )\n",
    "                    data = get_data_stat(data, store_in_data=True, verbose=args.debug)\n",
    "\n",
    "                    # initialize model\n",
    "                    model = get_model(\n",
    "                        gnn_arch=args.gnn_arch,\n",
    "                        feat_dim=data.n_feat,\n",
    "                        hid_dim=args.hid_dim,\n",
    "                        out_dim=data.n_class,\n",
    "                        n_layer=args.n_layer,\n",
    "                        device=device,\n",
    "                    )\n",
    "                    # tobe augmenter\n",
    "                    augmenter = BatAugmenter(mode=bat_mode, random_state=seed)\n",
    "                    # trainer\n",
    "                    trainer = NodeClassificationTrainer(\n",
    "                        model=model,\n",
    "                        data=data,\n",
    "                        device=device,\n",
    "                        augmenter=augmenter,  # BAT augmentation, to disable, set augmenter=None\n",
    "                        learning_rate=args.lr,\n",
    "                        weight_decay=args.weight_decay,\n",
    "                        train_epoch=args.epochs,\n",
    "                        early_stop_patience=args.early_stop,\n",
    "                        eval_freq=1,\n",
    "                        verbose_freq=None,\n",
    "                        enable_tqdm=args.tqdm,\n",
    "                        random_state=seed,\n",
    "                    )\n",
    "                    # train the GNN with BAT augmentation\n",
    "                    best_model = trainer.train()\n",
    "                    # print best results\n",
    "                    print (f'Run {i_run}: ', end='')\n",
    "                    trainer.print_best_results()\n",
    "                    # save best results\n",
    "                    best_results.append(trainer.best_eval_results)\n",
    "\n",
    "                # print the average performance of the best model\n",
    "                info = f\"Avg Test Performance ({args.n_runs} runs): \"\n",
    "                for metric in trainer.eval_metrics.keys():\n",
    "                    scores = np.array(\n",
    "                        [\n",
    "                            best_results[i][metric][\"test\"] * 100\n",
    "                            for i in range(len(best_results))\n",
    "                        ]\n",
    "                    )\n",
    "                    info += f\" | {metric.upper()}: {scores.mean():.2f} ± {scores.std()/(len(scores)**0.5):.2f}\"\n",
    "                print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
