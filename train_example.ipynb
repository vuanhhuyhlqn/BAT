{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from args import parse_args\n",
    "from baselines import *\n",
    "from data_utils import (\n",
    "    get_data_stat,\n",
    "    get_natural_imbalanced_split_data,\n",
    "    get_step_imbalanced_split_data,\n",
    "    load_data,\n",
    ")\n",
    "from bat import BatAugmenter\n",
    "from trainer import NodeClassificationTrainer\n",
    "from utils import get_model, get_device, print_centered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Experiment\n",
    "\n",
    "This script will run experiments on all the combinations of following settings (specified by the global variables below):\n",
    "\n",
    "| Setting         | (Default) Values                           | Description                                                        |\n",
    "| --------------- | ------------------------------------------ | ------------------------------------------------------------------ |\n",
    "| `DATASET_SPACE` | `['cora', 'citeseer', 'pubmed']`           | The datasets to use.                                               |\n",
    "| `IMB_TYPES`     | `{'step': [10, 20], 'natural': [50, 100]}` | The imbalance types and ratios.                                    |\n",
    "| `BAT_MODES`    | `['dummy', 'bat0', 'bat1']`                 | The BAT modes to test, `dummy` means no topological augmentation. |\n",
    "\n",
    "For other settings, we use the default values specified in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Experiment Setup \"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.argv = [\"\"]\n",
    "args = parse_args()\n",
    "\n",
    "DATASET_SPACE = [\"citeseer\"]\n",
    "MODE_SPACE = [\"dummy\", \"bat1\"]\n",
    "IMB_SPACE = {\n",
    "    \"step\": [10],\n",
    "    \"natural\": [50],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using GPU #0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Run experiment with\n",
      "  - Datasets:        ['citeseer']\n",
      "  - BAT modes:      ['dummy', 'bat1']\n",
      "  - Imbalance types: {'step': [10], 'natural': [50]}\n",
      "\n",
      "============== Arguments ==============\n",
      "gpu_id       : 0\n",
      "seed         : 42\n",
      "n_runs       : 3\n",
      "debug        : False\n",
      "dataset      : citeseer\n",
      "imb_type     : natural\n",
      "imb_ratio    : 50\n",
      "gnn_arch     : SAGE\n",
      "n_layer      : 3\n",
      "hid_dim      : 256\n",
      "lr           : 0.01\n",
      "weight_decay : 0.0005\n",
      "epochs       : 500\n",
      "early_stop   : 50\n",
      "tqdm         : False\n",
      "bat_mode     : all\n",
      "========================================\n",
      "\n",
      "////////////////////////// Experiment: Imbalance Type [Step] - Ratio [10] //////////////////////////\n",
      "\n",
      "============================ Dataset [Citeseer] - Independent Runs [3] ============================\n",
      "===================== Setting: Dataset [Citeseer] - StepIR [10] - BAT [dummy] =====================\n",
      "Run 1: Best Epoch:   68 | train/val/test | ACC: 100.0/42.80/45.00 | BACC: 100.0/40.46/42.73 | MACRO-F1: 100.0/35.19/38.54 | aug time: 0.00ms \n",
      "Run 2: Best Epoch:   62 | train/val/test | ACC: 100.0/52.80/48.60 | BACC: 100.0/49.80/47.91 | MACRO-F1: 100.0/47.24/45.10 | aug time: 0.00ms \n",
      "Run 3: Best Epoch:   95 | train/val/test | ACC: 100.0/42.80/40.90 | BACC: 100.0/43.88/42.96 | MACRO-F1: 100.0/39.64/38.64 | aug time: 0.00ms \n",
      "Avg Test Performance (3 runs):  | ACC: 44.83 ± 1.82 | BACC: 44.53 ± 1.38 | MACRO-F1: 40.76 ± 1.77\n",
      "====================== Setting: Dataset [Citeseer] - StepIR [10] - BAT [bat1] ======================\n",
      "Run 1: Best Epoch:  120 | train/val/test | ACC: 100.0/66.60/65.20 | BACC: 100.0/63.76/63.02 | MACRO-F1: 100.0/62.75/62.12 | aug time: 18.06ms \n",
      "Run 2: Best Epoch:   67 | train/val/test | ACC: 100.0/65.60/64.10 | BACC: 100.0/62.00/61.09 | MACRO-F1: 100.0/61.83/61.00 | aug time: 18.45ms \n",
      "Run 3: Best Epoch:  142 | train/val/test | ACC: 100.0/65.00/61.60 | BACC: 100.0/63.16/59.77 | MACRO-F1: 100.0/61.72/59.19 | aug time: 18.34ms \n",
      "Avg Test Performance (3 runs):  | ACC: 63.63 ± 0.87 | BACC: 61.29 ± 0.77 | MACRO-F1: 60.77 ± 0.70\n",
      "\n",
      "//////////////////////// Experiment: Imbalance Type [Natural] - Ratio [50] ////////////////////////\n",
      "\n",
      "============================ Dataset [Citeseer] - Independent Runs [3] ============================\n",
      "==================== Setting: Dataset [Citeseer] - NaturalIR [50] - BAT [dummy] ====================\n",
      "Run 1: Best Epoch:   28 | train/val/test | ACC: 97.75/54.94/54.88 | BACC: 75.00/48.43/48.47 | MACRO-F1: 74.44/44.18/44.32 | aug time: 0.00ms \n",
      "Run 2: Best Epoch:  133 | train/val/test | ACC: 100.0/52.16/51.91 | BACC: 100.0/46.75/46.43 | MACRO-F1: 100.0/44.71/44.19 | aug time: 0.00ms \n",
      "Run 3: Best Epoch:   69 | train/val/test | ACC: 100.0/53.83/53.46 | BACC: 100.0/47.65/47.54 | MACRO-F1: 100.0/43.74/43.62 | aug time: 0.00ms \n",
      "Avg Test Performance (3 runs):  | ACC: 53.42 ± 0.70 | BACC: 47.48 ± 0.48 | MACRO-F1: 44.04 ± 0.18\n",
      "==================== Setting: Dataset [Citeseer] - NaturalIR [50] - BAT [bat1] ====================\n",
      "Run 1: Best Epoch:  110 | train/val/test | ACC: 100.0/66.63/64.75 | BACC: 100.0/60.67/59.02 | MACRO-F1: 100.0/59.53/58.00 | aug time: 19.40ms \n",
      "Run 2: Best Epoch:   52 | train/val/test | ACC: 100.0/57.17/55.37 | BACC: 100.0/52.22/50.62 | MACRO-F1: 100.0/50.56/49.14 | aug time: 19.58ms \n",
      "Run 3: Best Epoch:   39 | train/val/test | ACC: 100.0/62.11/61.67 | BACC: 100.0/55.86/55.52 | MACRO-F1: 100.0/53.51/53.38 | aug time: 19.17ms \n",
      "Avg Test Performance (3 runs):  | ACC: 60.60 ± 2.25 | BACC: 55.05 ± 1.99 | MACRO-F1: 53.50 ± 2.09\n"
     ]
    }
   ],
   "source": [
    "device = get_device(args.gpu_id)\n",
    "log_width = 100\n",
    "\n",
    "print(\n",
    "    f\"Run experiment with\\n\"\n",
    "    f\"  - Datasets:        {DATASET_SPACE}\\n\"\n",
    "    f\"  - BAT modes:      {MODE_SPACE}\\n\"\n",
    "    f\"  - Imbalance types: {IMB_SPACE}\\n\"\n",
    ")\n",
    "\n",
    "print_centered(\"Arguments\", 40, fillchar=\"=\")\n",
    "kwlen = max([len(k) for k in args.__dict__.keys()]) + 1\n",
    "for keys, values in args.__dict__.items():\n",
    "    print(f\"{keys:{kwlen}}: {values}\")\n",
    "print_centered(\"\", 40, fillchar=\"=\")\n",
    "\n",
    "# run the experiment\n",
    "\n",
    "for imb_type in IMB_SPACE.keys():  # loop over imbalance types\n",
    "\n",
    "    for imb_ratio in IMB_SPACE[imb_type]:  # loop over imbalance ratios\n",
    "\n",
    "        print_centered(\n",
    "            f\"Experiment: Imbalance Type [{imb_type.title()}] - Ratio [{imb_ratio}]\",\n",
    "            log_width,\n",
    "            fillchar=\"/\",\n",
    "            prefix=\"\\n\",\n",
    "        )\n",
    "\n",
    "        for dataset in DATASET_SPACE:  # loop over datasets\n",
    "\n",
    "            print_centered(\n",
    "                f\"Dataset [{dataset.title()}] - Independent Runs [{args.n_runs}]\", log_width, fillchar=\"=\", prefix=\"\\n\"\n",
    "            )\n",
    "\n",
    "            args.imb_type = imb_type\n",
    "            args.imb_ratio = imb_ratio\n",
    "            args.dataset = dataset\n",
    "\n",
    "            for bat_mode in MODE_SPACE:  # loop over BAT modes\n",
    "\n",
    "                print_centered(\n",
    "                    f\"Setting: Dataset [{args.dataset.title()}] - {args.imb_type.title()}IR [{args.imb_ratio}] - BAT [{bat_mode}]\",\n",
    "                    log_width,\n",
    "                    fillchar=\"=\",\n",
    "                )\n",
    "\n",
    "                best_results = []\n",
    "                for i_run in range(1, args.n_runs + 1):\n",
    "                    seed = args.seed + i_run\n",
    "\n",
    "                    # load imbalanced data\n",
    "                    data = load_data(args.dataset, to_device=device, verbose=args.debug)\n",
    "                    if args.imb_type == \"step\":\n",
    "                        data = get_step_imbalanced_split_data(\n",
    "                            data,\n",
    "                            imbratio=args.imb_ratio,\n",
    "                            random_seed=seed,\n",
    "                            verbose=args.debug,\n",
    "                        )\n",
    "                    elif args.imb_type == \"natural\":\n",
    "                        data = get_natural_imbalanced_split_data(\n",
    "                            data,\n",
    "                            imbratio=args.imb_ratio,\n",
    "                            random_seed=seed,\n",
    "                            verbose=args.debug,\n",
    "                        )\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"imb_type must be one of ['step', 'natural'], got {args.imb_type}.\"\n",
    "                        )\n",
    "                    data = get_data_stat(data, store_in_data=True, verbose=args.debug)\n",
    "\n",
    "                    # initialize model\n",
    "                    model = get_model(\n",
    "                        gnn_arch=args.gnn_arch,\n",
    "                        feat_dim=data.n_feat,\n",
    "                        hid_dim=args.hid_dim,\n",
    "                        out_dim=data.n_class,\n",
    "                        n_layer=args.n_layer,\n",
    "                        device=device,\n",
    "                    )\n",
    "                    # tobe augmenter\n",
    "                    augmenter = BatAugmenter(mode=bat_mode, random_state=seed)\n",
    "                    # trainer\n",
    "                    trainer = NodeClassificationTrainer(\n",
    "                        model=model,\n",
    "                        data=data,\n",
    "                        device=device,\n",
    "                        augmenter=augmenter,  # BAT augmentation, to disable, set augmenter=None\n",
    "                        learning_rate=args.lr,\n",
    "                        weight_decay=args.weight_decay,\n",
    "                        train_epoch=args.epochs,\n",
    "                        early_stop_patience=args.early_stop,\n",
    "                        eval_freq=1,\n",
    "                        verbose_freq=None,\n",
    "                        enable_tqdm=args.tqdm,\n",
    "                        random_state=seed,\n",
    "                    )\n",
    "                    # train the GNN with BAT augmentation\n",
    "                    best_model = trainer.train()\n",
    "                    # print best results\n",
    "                    print (f'Run {i_run}: ', end='')\n",
    "                    trainer.print_best_results()\n",
    "                    # save best results\n",
    "                    best_results.append(trainer.best_eval_results)\n",
    "\n",
    "                # print the average performance of the best model\n",
    "                info = f\"Avg Test Performance ({args.n_runs} runs): \"\n",
    "                for metric in trainer.eval_metrics.keys():\n",
    "                    scores = np.array(\n",
    "                        [\n",
    "                            best_results[i][metric][\"test\"] * 100\n",
    "                            for i in range(len(best_results))\n",
    "                        ]\n",
    "                    )\n",
    "                    info += f\" | {metric.upper()}: {scores.mean():.2f} ± {scores.std()/(len(scores)**0.5):.2f}\"\n",
    "                print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
