{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from args import parse_args\n",
    "from baselines import *\n",
    "from data_utils import (\n",
    "    get_data_stat,\n",
    "    get_natural_imbalanced_split_data,\n",
    "    get_step_imbalanced_split_data,\n",
    "    load_data,\n",
    ")\n",
    "from bat import BatAugmenter\n",
    "from trainer import NodeClassificationTrainer\n",
    "from utils import get_model, get_device, print_centered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Experiment\n",
    "\n",
    "This script will run experiments on all the combinations of following settings (specified by the global variables below):\n",
    "\n",
    "| Setting         | (Default) Values                           | Description                                                        |\n",
    "| --------------- | ------------------------------------------ | ------------------------------------------------------------------ |\n",
    "| `DATASET_SPACE` | `['cora', 'citeseer', 'pubmed']`           | The datasets to use.                                               |\n",
    "| `IMB_TYPES`     | `{'step': [10, 20], 'natural': [50, 100]}` | The imbalance types and ratios.                                    |\n",
    "| `BAT_MODES`    | `['dummy', 'bat0', 'bat1']`                 | The BAT modes to test, `dummy` means no topological augmentation. |\n",
    "\n",
    "For other settings, we use the default values specified in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Experiment Setup \"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.argv = [\"\"]\n",
    "args = parse_args()\n",
    "\n",
    "DATASET_SPACE = [\"pubmed\"]\n",
    "MODE_SPACE = [\"dummy\", \"bat1\"]\n",
    "IMB_SPACE = {\n",
    "    \"step\": [10],\n",
    "    \"natural\": [50],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using GPU #0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Run experiment with\n",
      "  - Datasets:        ['pubmed']\n",
      "  - BAT modes:      ['dummy', 'bat1']\n",
      "  - Imbalance types: {'step': [10], 'natural': [50]}\n",
      "\n",
      "============== Arguments ==============\n",
      "gpu_id       : 0\n",
      "seed         : 42\n",
      "n_runs       : 3\n",
      "debug        : False\n",
      "dataset      : cora\n",
      "imb_type     : step\n",
      "imb_ratio    : 10\n",
      "gnn_arch     : SAGE\n",
      "n_layer      : 3\n",
      "hid_dim      : 256\n",
      "lr           : 0.01\n",
      "weight_decay : 0.0005\n",
      "epochs       : 500\n",
      "early_stop   : 50\n",
      "tqdm         : False\n",
      "bat_mode     : all\n",
      "========================================\n",
      "\n",
      "////////////////////////// Experiment: Imbalance Type [Step] - Ratio [10] //////////////////////////\n",
      "\n",
      "============================= Dataset [Pubmed] - Independent Runs [3] =============================\n",
      "====================== Setting: Dataset [Pubmed] - StepIR [10] - BAT [dummy] ======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor loader time: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/500 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 101\u001b[0m\n\u001b[0;32m     86\u001b[0m trainer \u001b[38;5;241m=\u001b[39m NodeClassificationTrainer(\n\u001b[0;32m     87\u001b[0m \tmodel\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     88\u001b[0m \tdata\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \trandom_state\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m     99\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# train the GNN with BAT augmentation\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# print best results\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\trainer.py:430\u001b[0m, in \u001b[0;36mNodeClassificationTrainer.train\u001b[1;34m(self, train_epoch, eval_freq, verbose_freq, return_best_model)\u001b[0m\n\u001b[0;32m    423\u001b[0m epoch_range \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    424\u001b[0m     trange(\u001b[38;5;241m1\u001b[39m, train_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtqdm_flag\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, train_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    427\u001b[0m )\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epoch_range:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;66;03m# update the model parameters\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;66;03m# evaluate the model on the validation set every eval_freq epochs\u001b[39;00m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\trainer.py:235\u001b[0m, in \u001b[0;36mNodeClassificationTrainer.model_update\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    231\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# training with mini-batch through neighbor_loader\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_neighbor_loader:\n\u001b[0;32m    236\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    237\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1492\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1492\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1495\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1454\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1454\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1456\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1285\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = get_device(args.gpu_id)\n",
    "log_width = 100\n",
    "\n",
    "print(\n",
    "\tf\"Run experiment with\\n\"\n",
    "\tf\"  - Datasets:        {DATASET_SPACE}\\n\"\n",
    "\tf\"  - BAT modes:      {MODE_SPACE}\\n\"\n",
    "\tf\"  - Imbalance types: {IMB_SPACE}\\n\"\n",
    ")\n",
    "\n",
    "print_centered(\"Arguments\", 40, fillchar=\"=\")\n",
    "kwlen = max([len(k) for k in args.__dict__.keys()]) + 1\n",
    "for keys, values in args.__dict__.items():\n",
    "\tprint(f\"{keys:{kwlen}}: {values}\")\n",
    "print_centered(\"\", 40, fillchar=\"=\")\n",
    "\n",
    "# run the experiment\n",
    "\n",
    "for imb_type in IMB_SPACE.keys():  # loop over imbalance types\n",
    "\n",
    "\tfor imb_ratio in IMB_SPACE[imb_type]:  # loop over imbalance ratios\n",
    "\n",
    "\t\tprint_centered(\n",
    "\t\t\tf\"Experiment: Imbalance Type [{imb_type.title()}] - Ratio [{imb_ratio}]\",\n",
    "\t\t\tlog_width,\n",
    "\t\t\tfillchar=\"/\",\n",
    "\t\t\tprefix=\"\\n\",\n",
    "\t\t)\n",
    "\n",
    "\t\tfor dataset in DATASET_SPACE:  # loop over datasets\n",
    "\n",
    "\t\t\tprint_centered(\n",
    "\t\t\t\tf\"Dataset [{dataset.title()}] - Independent Runs [{args.n_runs}]\", log_width, fillchar=\"=\", prefix=\"\\n\"\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\targs.imb_type = imb_type\n",
    "\t\t\targs.imb_ratio = imb_ratio\n",
    "\t\t\targs.dataset = dataset\n",
    "\n",
    "\t\t\tfor bat_mode in MODE_SPACE:  # loop over BAT modes\n",
    "\n",
    "\t\t\t\tprint_centered(\n",
    "\t\t\t\t\tf\"Setting: Dataset [{args.dataset.title()}] - {args.imb_type.title()}IR [{args.imb_ratio}] - BAT [{bat_mode}]\",\n",
    "\t\t\t\t\tlog_width,\n",
    "\t\t\t\t\tfillchar=\"=\",\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\tbest_results = []\n",
    "\t\t\t\tfor i_run in range(1, args.n_runs + 1):\n",
    "\t\t\t\t\tseed = args.seed + i_run\n",
    "\n",
    "\t\t\t\t\t# load imbalanced data\n",
    "\t\t\t\t\tdata = load_data(args.dataset, to_device='cpu', verbose=args.debug)\n",
    "\t\t\t\t\tif args.imb_type == \"step\":\n",
    "\t\t\t\t\t\tdata = get_step_imbalanced_split_data(\n",
    "\t\t\t\t\t\t\tdata,\n",
    "\t\t\t\t\t\t\timbratio=args.imb_ratio,\n",
    "\t\t\t\t\t\t\trandom_seed=seed,\n",
    "\t\t\t\t\t\t\tverbose=args.debug,\n",
    "\t\t\t\t\t\t)\n",
    "\t\t\t\t\telif args.imb_type == \"natural\":\n",
    "\t\t\t\t\t\tdata = get_natural_imbalanced_split_data(\n",
    "\t\t\t\t\t\t\tdata,\n",
    "\t\t\t\t\t\t\timbratio=args.imb_ratio,\n",
    "\t\t\t\t\t\t\trandom_seed=seed,\n",
    "\t\t\t\t\t\t\tverbose=args.debug,\n",
    "\t\t\t\t\t\t)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\traise ValueError(\n",
    "\t\t\t\t\t\t\tf\"imb_type must be one of ['step', 'natural'], got {args.imb_type}.\"\n",
    "\t\t\t\t\t\t)\n",
    "\t\t\t\t\tdata = get_data_stat(data, store_in_data=True, verbose=args.debug)\n",
    "\t\t\t\t\tdata.to('cpu')\n",
    "\t\t\t\t\t# initialize model\n",
    "\t\t\t\t\tmodel = get_model(\n",
    "\t\t\t\t\t\tgnn_arch=args.gnn_arch,\n",
    "\t\t\t\t\t\tfeat_dim=data.n_feat,\n",
    "\t\t\t\t\t\thid_dim=args.hid_dim,\n",
    "\t\t\t\t\t\tout_dim=data.n_class,\n",
    "\t\t\t\t\t\tn_layer=args.n_layer,\n",
    "\t\t\t\t\t\tdevice=device,\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\t# tobe augmenter\n",
    "\t\t\t\t\taugmenter = BatAugmenter(mode=bat_mode, random_state=seed)\n",
    "\t\t\t\t\t# trainer\n",
    "\t\t\t\t\ttrainer = NodeClassificationTrainer(\n",
    "\t\t\t\t\t\tmodel=model,\n",
    "\t\t\t\t\t\tdata=data,\n",
    "\t\t\t\t\t\tdevice=device,\n",
    "\t\t\t\t\t\taugmenter=augmenter,  # BAT augmentation, to disable, set augmenter=None\n",
    "\t\t\t\t\t\tlearning_rate=args.lr,\n",
    "\t\t\t\t\t\tweight_decay=args.weight_decay,\n",
    "\t\t\t\t\t\ttrain_epoch=args.epochs,\n",
    "\t\t\t\t\t\tearly_stop_patience=args.early_stop,\n",
    "\t\t\t\t\t\teval_freq=1,\n",
    "\t\t\t\t\t\tverbose_freq=None,\n",
    "\t\t\t\t\t\tenable_tqdm=True,\n",
    "\t\t\t\t\t\trandom_state=seed,\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\t# train the GNN with BAT augmentation\n",
    "\t\t\t\t\tbest_model = trainer.train()\n",
    "\t\t\t\t\t# print best results\n",
    "\t\t\t\t\tprint (f'Run {i_run}: ', end='')\n",
    "\t\t\t\t\ttrainer.print_best_results()\n",
    "\t\t\t\t\t# save best results\n",
    "\t\t\t\t\tbest_results.append(trainer.best_eval_results)\n",
    "\n",
    "\t\t\t\t# print the average performance of the best model\n",
    "\t\t\t\tinfo = f\"Avg Test Performance ({args.n_runs} runs): \"\n",
    "\t\t\t\tfor metric in trainer.eval_metrics.keys():\n",
    "\t\t\t\t\tscores = np.array(\n",
    "\t\t\t\t\t\t[\n",
    "\t\t\t\t\t\t\tbest_results[i][metric][\"test\"] * 100\n",
    "\t\t\t\t\t\t\tfor i in range(len(best_results))\n",
    "\t\t\t\t\t\t]\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\tinfo += f\" | {metric.upper()}: {scores.mean():.2f} Â± {scores.std()/(len(scores)**0.5):.2f}\"\n",
    "\t\t\t\tprint(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
