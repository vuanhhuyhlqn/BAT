{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from args import parse_args\n",
    "from baselines import *\n",
    "from data_utils import (\n",
    "    get_data_stat,\n",
    "    get_natural_imbalanced_split_data,\n",
    "    get_step_imbalanced_split_data,\n",
    "    load_data,\n",
    ")\n",
    "from bat import BatAugmenter\n",
    "from trainer import NodeClassificationTrainer\n",
    "from utils import get_model, get_device, print_centered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Experiment\n",
    "\n",
    "This script will run experiments on all the combinations of following settings (specified by the global variables below):\n",
    "\n",
    "| Setting         | (Default) Values                           | Description                                                        |\n",
    "| --------------- | ------------------------------------------ | ------------------------------------------------------------------ |\n",
    "| `DATASET_SPACE` | `['cora', 'citeseer', 'pubmed']`           | The datasets to use.                                               |\n",
    "| `IMB_TYPES`     | `{'step': [10, 20], 'natural': [50, 100]}` | The imbalance types and ratios.                                    |\n",
    "| `BAT_MODES`    | `['dummy', 'bat0', 'bat1']`                 | The BAT modes to test, `dummy` means no topological augmentation. |\n",
    "\n",
    "For other settings, we use the default values specified in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Experiment Setup \"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.argv = [\"\"]\n",
    "args = parse_args()\n",
    "\n",
    "DATASET_SPACE = [\"reddit\"]\n",
    "MODE_SPACE = [\"bat1\"]\n",
    "IMB_SPACE = {\n",
    "    \"step\": [10, 20],\n",
    "    \"natural\": [50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using GPU #0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Run experiment with\n",
      "  - Datasets:        ['reddit']\n",
      "  - BAT modes:      ['bat1']\n",
      "  - Imbalance types: {'step': [10, 20], 'natural': [50, 100]}\n",
      "\n",
      "============== Arguments ==============\n",
      "gpu_id       : 0\n",
      "seed         : 42\n",
      "n_runs       : 3\n",
      "debug        : False\n",
      "dataset      : cora\n",
      "imb_type     : step\n",
      "imb_ratio    : 10\n",
      "gnn_arch     : SAGE\n",
      "n_layer      : 3\n",
      "hid_dim      : 256\n",
      "lr           : 0.01\n",
      "weight_decay : 0.0005\n",
      "epochs       : 500\n",
      "early_stop   : 50\n",
      "tqdm         : False\n",
      "bat_mode     : all\n",
      "========================================\n",
      "\n",
      "////////////////////////// Experiment: Imbalance Type [Step] - Ratio [10] //////////////////////////\n",
      "\n",
      "============================= Dataset [Reddit] - Independent Runs [3] =============================\n",
      "======================= Setting: Dataset [Reddit] - StepIR [10] - BAT [bat1] =======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.dgl.ai/dataset/reddit.zip\n",
      "Extracting data\\Reddit\\raw\\reddit.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 257.04 GiB. GPU 0 has a total capacity of 4.00 GiB of which 974.25 MiB is free. Of the allocated memory 2.24 GiB is allocated by PyTorch, and 23.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 101\u001b[0m\n\u001b[0;32m     86\u001b[0m trainer \u001b[38;5;241m=\u001b[39m NodeClassificationTrainer(\n\u001b[0;32m     87\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     88\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m     99\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# train the GNN with BAT augmentation\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# print best results\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\trainer.py:378\u001b[0m, in \u001b[0;36mNodeClassificationTrainer.train\u001b[1;34m(self, train_epoch, eval_freq, verbose_freq, return_best_model)\u001b[0m\n\u001b[0;32m    371\u001b[0m epoch_range \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    372\u001b[0m     trange(\u001b[38;5;241m1\u001b[39m, train_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtqdm_flag\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, train_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    375\u001b[0m )\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epoch_range:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# update the model parameters\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;66;03m# evaluate the model on the validation set every eval_freq epochs\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\trainer.py:207\u001b[0m, in \u001b[0;36mNodeClassificationTrainer.model_update\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# perform graph augmentation\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_epoch:\n\u001b[1;32m--> 207\u001b[0m     x, edge_index, aug_runtime_info \u001b[38;5;241m=\u001b[39m \u001b[43maugmenter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m     y, train_mask \u001b[38;5;241m=\u001b[39m augmenter\u001b[38;5;241m.\u001b[39madapt_labels_and_train_mask(y, train_mask)\n\u001b[0;32m    210\u001b[0m augmented_data \u001b[38;5;241m=\u001b[39m Data(x\u001b[38;5;241m=\u001b[39mx, edge_index\u001b[38;5;241m=\u001b[39medge_index, y\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\bat.py:339\u001b[0m, in \u001b[0;36mBatAugmenter.augment\u001b[1;34m(self, model, x, edge_index)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# initialization\u001b[39;00m\n\u001b[0;32m    338\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 339\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred_proba\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    341\u001b[0m y_pred[train_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\bat.py:469\u001b[0m, in \u001b[0;36mBatAugmenter.predict_proba\u001b[1;34m(model, x, edge_index, return_numpy)\u001b[0m\n\u001b[0;32m    467\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 469\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m pred_proba \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_numpy:\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\nets\\sage.py:84\u001b[0m, in \u001b[0;36mGraphSAGEX.forward\u001b[1;34m(self, x, adj)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj):\n\u001b[0;32m     82\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m adj\n\u001b[1;32m---> 84\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iter_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvx:\n\u001b[0;32m     87\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_p, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[0;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_pscwaj8u.py:173\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, size)\u001b[0m\n\u001b[0;32m    167\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    168\u001b[0m         out,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_pscwaj8u.py:83\u001b[0m, in \u001b[0;36mcollect\u001b[1;34m(self, edge_index, x, size)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, \u001b[38;5;241m0\u001b[39m, _x_0)\n\u001b[1;32m---> 83\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:267\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:290\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)):\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m that are larger \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:271\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 257.04 GiB. GPU 0 has a total capacity of 4.00 GiB of which 974.25 MiB is free. Of the allocated memory 2.24 GiB is allocated by PyTorch, and 23.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "device = get_device(args.gpu_id)\n",
    "log_width = 100\n",
    "\n",
    "print(\n",
    "    f\"Run experiment with\\n\"\n",
    "    f\"  - Datasets:        {DATASET_SPACE}\\n\"\n",
    "    f\"  - BAT modes:      {MODE_SPACE}\\n\"\n",
    "    f\"  - Imbalance types: {IMB_SPACE}\\n\"\n",
    ")\n",
    "\n",
    "print_centered(\"Arguments\", 40, fillchar=\"=\")\n",
    "kwlen = max([len(k) for k in args.__dict__.keys()]) + 1\n",
    "for keys, values in args.__dict__.items():\n",
    "    print(f\"{keys:{kwlen}}: {values}\")\n",
    "print_centered(\"\", 40, fillchar=\"=\")\n",
    "\n",
    "# run the experiment\n",
    "\n",
    "for imb_type in IMB_SPACE.keys():  # loop over imbalance types\n",
    "\n",
    "    for imb_ratio in IMB_SPACE[imb_type]:  # loop over imbalance ratios\n",
    "\n",
    "        print_centered(\n",
    "            f\"Experiment: Imbalance Type [{imb_type.title()}] - Ratio [{imb_ratio}]\",\n",
    "            log_width,\n",
    "            fillchar=\"/\",\n",
    "            prefix=\"\\n\",\n",
    "        )\n",
    "\n",
    "        for dataset in DATASET_SPACE:  # loop over datasets\n",
    "\n",
    "            print_centered(\n",
    "                f\"Dataset [{dataset.title()}] - Independent Runs [{args.n_runs}]\", log_width, fillchar=\"=\", prefix=\"\\n\"\n",
    "            )\n",
    "\n",
    "            args.imb_type = imb_type\n",
    "            args.imb_ratio = imb_ratio\n",
    "            args.dataset = dataset\n",
    "\n",
    "            for bat_mode in MODE_SPACE:  # loop over BAT modes\n",
    "\n",
    "                print_centered(\n",
    "                    f\"Setting: Dataset [{args.dataset.title()}] - {args.imb_type.title()}IR [{args.imb_ratio}] - BAT [{bat_mode}]\",\n",
    "                    log_width,\n",
    "                    fillchar=\"=\",\n",
    "                )\n",
    "\n",
    "                best_results = []\n",
    "                for i_run in range(1, args.n_runs + 1):\n",
    "                    seed = args.seed + i_run\n",
    "\n",
    "                    # load imbalanced data\n",
    "                    data = load_data(args.dataset, to_device=device, verbose=args.debug)\n",
    "                    if args.imb_type == \"step\":\n",
    "                        data = get_step_imbalanced_split_data(\n",
    "                            data,\n",
    "                            imbratio=args.imb_ratio,\n",
    "                            random_seed=seed,\n",
    "                            verbose=args.debug,\n",
    "                        )\n",
    "                    elif args.imb_type == \"natural\":\n",
    "                        data = get_natural_imbalanced_split_data(\n",
    "                            data,\n",
    "                            imbratio=args.imb_ratio,\n",
    "                            random_seed=seed,\n",
    "                            verbose=args.debug,\n",
    "                        )\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"imb_type must be one of ['step', 'natural'], got {args.imb_type}.\"\n",
    "                        )\n",
    "                    data = get_data_stat(data, store_in_data=True, verbose=args.debug)\n",
    "\n",
    "                    # initialize model\n",
    "                    model = get_model(\n",
    "                        gnn_arch=args.gnn_arch,\n",
    "                        feat_dim=data.n_feat,\n",
    "                        hid_dim=args.hid_dim,\n",
    "                        out_dim=data.n_class,\n",
    "                        n_layer=args.n_layer,\n",
    "                        device=device,\n",
    "                    )\n",
    "                    # tobe augmenter\n",
    "                    augmenter = BatAugmenter(mode=bat_mode, random_state=seed)\n",
    "                    # trainer\n",
    "                    trainer = NodeClassificationTrainer(\n",
    "                        model=model,\n",
    "                        data=data,\n",
    "                        device=device,\n",
    "                        augmenter=augmenter,  # BAT augmentation, to disable, set augmenter=None\n",
    "                        learning_rate=args.lr,\n",
    "                        weight_decay=args.weight_decay,\n",
    "                        train_epoch=args.epochs,\n",
    "                        early_stop_patience=args.early_stop,\n",
    "                        eval_freq=1,\n",
    "                        verbose_freq=None,\n",
    "                        enable_tqdm=args.tqdm,\n",
    "                        random_state=seed,\n",
    "                    )\n",
    "                    # train the GNN with BAT augmentation\n",
    "                    best_model = trainer.train()\n",
    "                    # print best results\n",
    "                    print (f'Run {i_run}: ', end='')\n",
    "                    trainer.print_best_results()\n",
    "                    # save best results\n",
    "                    best_results.append(trainer.best_eval_results)\n",
    "\n",
    "                # print the average performance of the best model\n",
    "                info = f\"Avg Test Performance ({args.n_runs} runs): \"\n",
    "                for metric in trainer.eval_metrics.keys():\n",
    "                    scores = np.array(\n",
    "                        [\n",
    "                            best_results[i][metric][\"test\"] * 100\n",
    "                            for i in range(len(best_results))\n",
    "                        ]\n",
    "                    )\n",
    "                    info += f\" | {metric.upper()}: {scores.mean():.2f} Â± {scores.std()/(len(scores)**0.5):.2f}\"\n",
    "                print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
