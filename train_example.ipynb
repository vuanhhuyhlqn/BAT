{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from args import parse_args\n",
    "from baselines import *\n",
    "from data_utils import (\n",
    "    get_data_stat,\n",
    "    get_natural_imbalanced_split_data,\n",
    "    get_step_imbalanced_split_data,\n",
    "    load_data,\n",
    ")\n",
    "from bat import BatAugmenter\n",
    "from trainer import NodeClassificationTrainer\n",
    "from utils import get_model, get_device, print_centered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Experiment\n",
    "\n",
    "This script will run experiments on all the combinations of following settings (specified by the global variables below):\n",
    "\n",
    "| Setting         | (Default) Values                           | Description                                                        |\n",
    "| --------------- | ------------------------------------------ | ------------------------------------------------------------------ |\n",
    "| `DATASET_SPACE` | `['cora', 'citeseer', 'pubmed']`           | The datasets to use.                                               |\n",
    "| `IMB_TYPES`     | `{'step': [10, 20], 'natural': [50, 100]}` | The imbalance types and ratios.                                    |\n",
    "| `BAT_MODES`    | `['dummy', 'bat0', 'bat1']`                 | The BAT modes to test, `dummy` means no topological augmentation. |\n",
    "\n",
    "For other settings, we use the default values specified in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Experiment Setup \"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.argv = [\"\"]\n",
    "args = parse_args()\n",
    "\n",
    "DATASET_SPACE = [\"citeseer\"]\n",
    "MODE_SPACE = [\"bat1\"]\n",
    "IMB_SPACE = {\n",
    "    \"step\": [10, 20],\n",
    "    \"natural\": [50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using GPU #0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Run experiment with\n",
      "  - Datasets:        ['citeseer']\n",
      "  - BAT modes:      ['bat1']\n",
      "  - Imbalance types: {'step': [10, 20], 'natural': [50, 100]}\n",
      "\n",
      "============== Arguments ==============\n",
      "gpu_id       : 0\n",
      "seed         : 42\n",
      "n_runs       : 3\n",
      "debug        : False\n",
      "dataset      : citeseer\n",
      "imb_type     : step\n",
      "imb_ratio    : 20\n",
      "gnn_arch     : SAGE\n",
      "n_layer      : 3\n",
      "hid_dim      : 256\n",
      "lr           : 0.01\n",
      "weight_decay : 0.0005\n",
      "epochs       : 500\n",
      "early_stop   : 50\n",
      "tqdm         : False\n",
      "bat_mode     : all\n",
      "========================================\n",
      "\n",
      "////////////////////////// Experiment: Imbalance Type [Step] - Ratio [10] //////////////////////////\n",
      "\n",
      "============================ Dataset [Citeseer] - Independent Runs [3] ============================\n",
      "====================== Setting: Dataset [Citeseer] - StepIR [10] - BAT [bat1] ======================\n",
      "Run 1: Best Epoch:   75 | train/val/test | ACC: 98.48/92.60/89.90 | BACC: 99.17/92.30/87.74 | MACRO-F1: 99.17/92.20/88.54 | aug time: 21.94ms \n",
      "Run 2: Best Epoch:  114 | train/val/test | ACC: 96.97/94.20/92.30 | BACC: 98.33/93.57/89.53 | MACRO-F1: 95.41/93.66/90.27 | aug time: 20.94ms \n",
      "Run 3: Best Epoch:  161 | train/val/test | ACC: 98.48/93.60/92.10 | BACC: 99.17/92.76/89.77 | MACRO-F1: 99.17/93.00/90.59 | aug time: 21.17ms \n",
      "Avg Test Performance (3 runs):  | ACC: 91.43 ± 0.63 | BACC: 89.01 ± 0.52 | MACRO-F1: 89.80 ± 0.52\n",
      "\n",
      "////////////////////////// Experiment: Imbalance Type [Step] - Ratio [20] //////////////////////////\n",
      "\n",
      "============================ Dataset [Citeseer] - Independent Runs [3] ============================\n",
      "====================== Setting: Dataset [Citeseer] - StepIR [20] - BAT [bat1] ======================\n",
      "Run 1: Best Epoch:  185 | train/val/test | ACC: 98.41/93.60/92.70 | BACC: 99.17/93.43/91.38 | MACRO-F1: 99.17/93.12/91.84 | aug time: 21.33ms \n",
      "Run 2: Best Epoch:  193 | train/val/test | ACC: 100.0/93.00/93.10 | BACC: 100.0/92.60/91.17 | MACRO-F1: 100.0/92.77/91.87 | aug time: 21.89ms \n",
      "Run 3: Best Epoch:   65 | train/val/test | ACC: 100.0/92.20/90.80 | BACC: 100.0/91.04/88.44 | MACRO-F1: 100.0/91.57/89.46 | aug time: 22.18ms \n",
      "Avg Test Performance (3 runs):  | ACC: 92.20 ± 0.58 | BACC: 90.33 ± 0.77 | MACRO-F1: 91.06 ± 0.65\n",
      "\n",
      "//////////////////////// Experiment: Imbalance Type [Natural] - Ratio [50] ////////////////////////\n",
      "\n",
      "============================ Dataset [Citeseer] - Independent Runs [3] ============================\n",
      "==================== Setting: Dataset [Citeseer] - NaturalIR [50] - BAT [bat1] ====================\n",
      "Run 1: Best Epoch:   97 | train/val/test | ACC: 100.0/89.12/88.95 | BACC: 100.0/87.20/86.69 | MACRO-F1: 100.0/87.53/87.09 | aug time: 22.71ms \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File saved_ckpt\\GraphSAGEX-3703-6.pt cannot be opened.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 101\u001b[0m\n\u001b[0;32m     86\u001b[0m trainer \u001b[38;5;241m=\u001b[39m NodeClassificationTrainer(\n\u001b[0;32m     87\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     88\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m     99\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# train the GNN with BAT augmentation\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# print best results\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\madmo\\Workspace\\BAT\\trainer.py:394\u001b[0m, in \u001b[0;36mNodeClassificationTrainer.train\u001b[1;34m(self, train_epoch, eval_freq, verbose_freq, return_best_model)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_valid_score \u001b[38;5;241m=\u001b[39m valid_score\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;66;03m# print (f\"///// Best model parameters updated at epoch {epoch} /////\")\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m early_stop_flag:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# stop training if the validation score does not improve for early_stop_rounds epochs\u001b[39;00m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m early_stop_patience:\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\serialization.py:966\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    963\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(f)\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 966\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    967\u001b[0m         _save(\n\u001b[0;32m    968\u001b[0m             obj,\n\u001b[0;32m    969\u001b[0m             opened_zipfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    972\u001b[0m             _disable_byteorder_record,\n\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\serialization.py:828\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\madmo\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\serialization.py:792\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    786\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream, get_crc32_options(), _get_storage_alignment()\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     )\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m--> 792\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_crc32_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_storage_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File saved_ckpt\\GraphSAGEX-3703-6.pt cannot be opened."
     ]
    }
   ],
   "source": [
    "device = get_device(args.gpu_id)\n",
    "log_width = 100\n",
    "\n",
    "print(\n",
    "    f\"Run experiment with\\n\"\n",
    "    f\"  - Datasets:        {DATASET_SPACE}\\n\"\n",
    "    f\"  - BAT modes:      {MODE_SPACE}\\n\"\n",
    "    f\"  - Imbalance types: {IMB_SPACE}\\n\"\n",
    ")\n",
    "\n",
    "print_centered(\"Arguments\", 40, fillchar=\"=\")\n",
    "kwlen = max([len(k) for k in args.__dict__.keys()]) + 1\n",
    "for keys, values in args.__dict__.items():\n",
    "    print(f\"{keys:{kwlen}}: {values}\")\n",
    "print_centered(\"\", 40, fillchar=\"=\")\n",
    "\n",
    "# run the experiment\n",
    "\n",
    "for imb_type in IMB_SPACE.keys():  # loop over imbalance types\n",
    "\n",
    "    for imb_ratio in IMB_SPACE[imb_type]:  # loop over imbalance ratios\n",
    "\n",
    "        print_centered(\n",
    "            f\"Experiment: Imbalance Type [{imb_type.title()}] - Ratio [{imb_ratio}]\",\n",
    "            log_width,\n",
    "            fillchar=\"/\",\n",
    "            prefix=\"\\n\",\n",
    "        )\n",
    "\n",
    "        for dataset in DATASET_SPACE:  # loop over datasets\n",
    "\n",
    "            print_centered(\n",
    "                f\"Dataset [{dataset.title()}] - Independent Runs [{args.n_runs}]\", log_width, fillchar=\"=\", prefix=\"\\n\"\n",
    "            )\n",
    "\n",
    "            args.imb_type = imb_type\n",
    "            args.imb_ratio = imb_ratio\n",
    "            args.dataset = dataset\n",
    "\n",
    "            for bat_mode in MODE_SPACE:  # loop over BAT modes\n",
    "\n",
    "                print_centered(\n",
    "                    f\"Setting: Dataset [{args.dataset.title()}] - {args.imb_type.title()}IR [{args.imb_ratio}] - BAT [{bat_mode}]\",\n",
    "                    log_width,\n",
    "                    fillchar=\"=\",\n",
    "                )\n",
    "\n",
    "                best_results = []\n",
    "                for i_run in range(1, args.n_runs + 1):\n",
    "                    seed = args.seed + i_run\n",
    "\n",
    "                    # load imbalanced data\n",
    "                    data = load_data(args.dataset, to_device=device, verbose=args.debug)\n",
    "                    if args.imb_type == \"step\":\n",
    "                        data = get_step_imbalanced_split_data(\n",
    "                            data,\n",
    "                            imbratio=args.imb_ratio,\n",
    "                            random_seed=seed,\n",
    "                            verbose=args.debug,\n",
    "                        )\n",
    "                    elif args.imb_type == \"natural\":\n",
    "                        data = get_natural_imbalanced_split_data(\n",
    "                            data,\n",
    "                            imbratio=args.imb_ratio,\n",
    "                            random_seed=seed,\n",
    "                            verbose=args.debug,\n",
    "                        )\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"imb_type must be one of ['step', 'natural'], got {args.imb_type}.\"\n",
    "                        )\n",
    "                    data = get_data_stat(data, store_in_data=True, verbose=args.debug)\n",
    "\n",
    "                    # initialize model\n",
    "                    model = get_model(\n",
    "                        gnn_arch=args.gnn_arch,\n",
    "                        feat_dim=data.n_feat,\n",
    "                        hid_dim=args.hid_dim,\n",
    "                        out_dim=data.n_class,\n",
    "                        n_layer=args.n_layer,\n",
    "                        device=device,\n",
    "                    )\n",
    "                    # tobe augmenter\n",
    "                    augmenter = BatAugmenter(mode=bat_mode, random_state=seed)\n",
    "                    # trainer\n",
    "                    trainer = NodeClassificationTrainer(\n",
    "                        model=model,\n",
    "                        data=data,\n",
    "                        device=device,\n",
    "                        augmenter=augmenter,  # BAT augmentation, to disable, set augmenter=None\n",
    "                        learning_rate=args.lr,\n",
    "                        weight_decay=args.weight_decay,\n",
    "                        train_epoch=args.epochs,\n",
    "                        early_stop_patience=args.early_stop,\n",
    "                        eval_freq=1,\n",
    "                        verbose_freq=None,\n",
    "                        enable_tqdm=args.tqdm,\n",
    "                        random_state=seed,\n",
    "                    )\n",
    "                    # train the GNN with BAT augmentation\n",
    "                    best_model = trainer.train()\n",
    "                    # print best results\n",
    "                    print (f'Run {i_run}: ', end='')\n",
    "                    trainer.print_best_results()\n",
    "                    # save best results\n",
    "                    best_results.append(trainer.best_eval_results)\n",
    "\n",
    "                # print the average performance of the best model\n",
    "                info = f\"Avg Test Performance ({args.n_runs} runs): \"\n",
    "                for metric in trainer.eval_metrics.keys():\n",
    "                    scores = np.array(\n",
    "                        [\n",
    "                            best_results[i][metric][\"test\"] * 100\n",
    "                            for i in range(len(best_results))\n",
    "                        ]\n",
    "                    )\n",
    "                    info += f\" | {metric.upper()}: {scores.mean():.2f} ± {scores.std()/(len(scores)**0.5):.2f}\"\n",
    "                print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
